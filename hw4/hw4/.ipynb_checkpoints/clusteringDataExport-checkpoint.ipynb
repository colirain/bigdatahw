{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf, lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark import SQLContext\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Clustering\")\\\n",
    "    .getOrCreate()\n",
    "# dataframe1 = spark.read.json('hdfs://localhost:1234/user/tl2861/hw3/train.json')\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "# dataframe1 = sqlContext.read.json('hdfs://localhost:1234/user/tl2861/hw3/train.json')\n",
    "dataframe1 = sqlContext.read.json('../../data/AA/wiki_*').withColumn('label',lit(0))\n",
    "dataframe2 = sqlContext.read.json('../../data/AAquote/wiki_*').withColumn('label', lit(1))\n",
    "# dataframe3 = sqlContext.read.json('../../data/AAvoyage/wiki_*').withColumn('label',lit(3))\n",
    "dataframe = dataframe1.unionAll(dataframe2)\n",
    "# dataframe1.printSchema()\n",
    "# dataframe2.printSchema()\n",
    "dataframe.printSchema()\n",
    "# dataframe1.show()\n",
    "#regexTokenizer = RegexTokenizer()\n",
    "sampledData = dataframe.sampleBy(\"label\", fractions={0: 0.2, 1: 0.2}, seed=0)\n",
    "# sampledData.show()\n",
    "# sampledData0 = pd.DataFrame(sampledData)\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"[^A-Za-z]+\", toLowercase=True)\n",
    "tokenizedData = regexTokenizer.transform(sampledData)\n",
    "\n",
    "stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "filteredData = stopWordsRemover.transform(tokenizedData)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(filteredData)\n",
    "\n",
    "idf= IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "data1 = idfModel.transform(featurizedData)\n",
    "\n",
    "datatext = data1.select('id','features','label')\n",
    "datatext.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopWordsRemover, hashingTF,idf])\n",
    "pipeline_model=pipeline.fit(sampledData)\n",
    "processed_data = pipeline_model.transform(sampledData)\n",
    "\n",
    "datatext.toPandas().to_csv(\"dataCluster.csv\", sep = \",\", index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "kmeans = KMeans().setK(2).setSeed(4381)\n",
    "kmModel = kmeans.fit(data1)\n",
    "wssse = kmModel.computeCost(data1)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "centers = kmModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "     print(center)\n",
    "        \n",
    "data_kmeans = data1.select('id','features','prediction')\n",
    "data_kmeans.toPandas().to_csv(\"dataCluster-kmeans.csv\",sep)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
