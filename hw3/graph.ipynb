{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf, lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark import SQLContext\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"graph\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe1 = sqlContext.read.json('hdfs://localhost:1234/user/tl2861/hw3/train.json')\n",
    "df3 = sqlContext.read.json('../../data/AA/wiki_*')\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.createOrReplaceTempView(\"wikinews\")\n",
    "# sqlDF3 = spark.sql(\"select count(*) from wikinews\")\n",
    "# sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"[^A-Za-z]+\", toLowercase=True)\n",
    "tokenizedData = regexTokenizer.transform(df3)\n",
    "stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "filteredData = stopWordsRemover.transform(tokenizedData)\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(filteredData)\n",
    "idf= IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "data1 = idfModel.transform(featurizedData)\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm\")\n",
    "data = normalizer.transform(data1)\n",
    "data = data.sample(False, 0.2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1.show()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29313942 0.12286993 0.11253153 ... 0.30024093 0.30916789 0.29102504]\n",
      " [0.25695014 0.15955723 0.2045847  ... 0.2079407  0.24088874 0.12957297]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.15396869 0.24585243 0.15761632 ... 0.12015139 0.18558571 0.12478215]\n",
      " [0.34789535 0.19442797 0.17806861 ... 0.1385702  0.11007534 0.41939731]\n",
      " [0.37162815 0.25961438 0.09510807 ... 0.16916938 0.19597414 0.42165444]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature = np.array(data.select('norm').collect())\n",
    "# delete the 1 size axis\n",
    "feature = np.squeeze(feature)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.25256538 0.17283795 0.24799582 ... 0.37072169 0.23484518 0.22808169]]\n",
      "\n",
      " [[0.13749049 0.21130778 0.1583412  ... 0.09388087 0.17400995 0.4289962 ]]\n",
      "\n",
      " [[0.15065896 0.2165108  0.28642376 ... 0.19594766 0.1089578  0.19535971]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.19696707 0.25160873 0.23043812 ... 0.23055856 0.40360325 0.19155563]]\n",
      "\n",
      " [[0.18648838 0.08933366 0.19090642 ... 0.31531182 0.08991329 0.15113736]]\n",
      "\n",
      " [[0.20378755 0.16270082 0.0298022  ... 0.21203754 0.39301555 0.4954718 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.dot(feature, feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75924657 0.14473213 ... 0.7827979  0.78997464 0.82221378]\n",
      " [0.75924657 1.         0.37213542 ... 0.82217253 0.83299421 0.8331656 ]\n",
      " [0.14473213 0.37213542 1.         ... 0.05212743 0.24047359 0.33027206]\n",
      " ...\n",
      " [0.7827979  0.82217253 0.05212743 ... 1.         0.82863578 0.71298453]\n",
      " [0.78997464 0.83299421 0.24047359 ... 0.82863578 1.         0.86095263]\n",
      " [0.82221378 0.8331656  0.33027206 ... 0.71298453 0.86095263 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
